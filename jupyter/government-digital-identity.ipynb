{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table width=100%>\n",
    "  <tr>\n",
    "    <td width=170px> <img src=\"../images/logo.png\" alt=\"Oxford Logo\" height=\"160\" width=\"160\"></td>\n",
    "    <td width=220px style=\"font-size: 35px; text-align:left\"> \n",
    "      <table>\n",
    "        <tr><td style=\"font-size: 30px; text-align:left\"> Universal Digital Identity: <br>NLP Analysis of Government Initiatives</td></tr>\n",
    "      </table>   \n",
    "    </td>\n",
    "    <td width=150>\n",
    " <table>\n",
    " <tr><td>  Matthew Comb (2910648)</td></tr>\n",
    "  <tr><td>matthew.comb@linacre.ox.ac.uk</td></tr>\n",
    " <tr><td>  Dr Andrew Martin</td></tr>\n",
    "  <tr><td>andrew.martin@kellogg.ox.ac.uk</td></tr>\n",
    "  </table>\n",
    "  </td></tr>\n",
    "</table>  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract <a class=\"anchor\" id=\"research-abstract\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Governments globally recognise digital identity as essential for a thriving digital economy. By implementing digital identity systems, they strive to streamline citizen services, more effectively combat fraud, improve regulatory oversight, ensure accessibility for marginalised groups, and cut costs linked to conventional paper-based methods. This comprehensive approach highlights some of the many benefits of digital identity in modern governance and economic systems.\n",
    "\n",
    "Implementing digital identity systems is, however, a complex challenge. The field, marked by over 6000 commercial patents filed worldwide, is now fragmented, and struggles with the significant challenge of interoperability between digital identity implementations. Currently, the landscape of digital identity is transforming owing to two key developments: the European Union's eIDAS regulatory reform, which aims to standardise electronic identification to enhance trust in online transactions, and the World Wide Web Consortium's Verifiable Credentials framework, which focuses on a decentralised approach that prioritises secure, private, and user-controlled digital identity verification. These initiatives involve a combination of centralised regulation and decentralised technology and bolster the prospects for a more unified approach to digital identity.\n",
    "\n",
    "This study primarily focuses on two objectives. Firstly, it employs natural language processing to analyse the strategies and developmental stages of key government digital identity programs. Secondly, the study identifies key patterns within these programmes vital for establishing a universally relevant digital identity framework. By considering various digital identity paradigms and frameworks, the research seeks to deepen the understanding of the digital identity field and highlight effective practices that could facilitate the broader adoption of a comprehensive digital identity model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents:\n",
    "\n",
    "* [Abstract](#research-abstract)\n",
    "* [Introduction](#introduction)\n",
    "* [Research Questions](#research-questions)\n",
    "* [Data Collection](#data-collection)\n",
    "* [Initialisation](#initialisation)\n",
    "* [Helper Functions](#helper-functions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction <a class=\"anchor\" id=\"introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Digital identity has become a critical component of modern governance, enabling governments to deliver services, enforce regulations, and support economic growth. Research into this domain often requires analyzing data from government websites, which serve as rich repositories of policies, frameworks, and updates related to digital identity systems. This Jupyter notebook provides a practical guide for data mining government websites to extract and analyze information relevant to digital identity.\n",
    "\n",
    "The sample code in this notebook demonstrates how to:\n",
    "\n",
    "1. **Identify and Scrape Relevant Web Pages**:\n",
    "   - Use web scraping libraries like `requests` and `BeautifulSoup` to extract content from government websites.\n",
    "   - Handle dynamic content using `Selenium` if necessary.\n",
    "\n",
    "2. **Preprocess and Clean the Data**:\n",
    "   - Remove unwanted elements like advertisements, navigation bars, and extraneous formatting.\n",
    "   - Structure the data for analysis by extracting meaningful sections, such as headers, paragraphs, and tables.\n",
    "\n",
    "3. **Perform Natural Language Processing (NLP)**:\n",
    "   - Tokenize, clean, and preprocess textual data for further analysis.\n",
    "   - Apply topic modeling, keyword extraction, or sentiment analysis to identify trends in digital identity discourse.\n",
    "\n",
    "4. **Analyze and Visualize Findings**:\n",
    "   - Summarize extracted data using word clouds, frequency distributions, or network diagrams.\n",
    "   - Highlight key terms, themes, and patterns that emerge from the analysis.\n",
    "\n",
    "This notebook is designed for researchers interested in studying government policies and practices on digital identity. The methods demonstrated here can be adapted to other domains requiring web data mining. By the end of this tutorial, you will have a foundational understanding of how to gather, process, and analyze data from government websites to support your research.\n",
    "\n",
    "> **Note**: Ensure you comply with the terms of service and legal guidelines of the websites you scrape. Some sites may prohibit automated scraping or require explicit permission.\n",
    "\n",
    "### Please Note\n",
    "\n",
    "Results from this sample code may not match the findings in related journal publications. This is because the sample code does not include the processing of PDF files linked on the webpages, which are integral to the full data mining package used in the research. Additionally, webpages are subject to constant updates over time, leading to potential variations in the extracted content.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Questions <a class=\"anchor\" id=\"research-questions\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Are governments aligned in their approach to digital identity solutions?**\n",
    "\n",
    "2. **What is the maturity of leading government digital identity programs?**\n",
    "\n",
    "3. **What published information do governments prioritize in their digital identity approach?**\n",
    "\n",
    "4. **What patterns have emerged in these developments that could pave the way for a stable and universal digital identity?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation <a class=\"anchor\" id=\"initialisation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import python data analysis library\n",
    "import pandas as pd\n",
    "\n",
    "# pd.set_option('max_columns', 120)\n",
    "# pd.set_option('max_rows', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scientific platform package\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML imports\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display import clear_output\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beautiful Soup\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set debug flag\n",
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# urllib\n",
    "from urllib.parse import urlparse, urljoin, urlunparse\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#system etc\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import unicodedata\n",
    "import csv\n",
    "import datetime\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering packages\n",
    "import sklearn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from scipy.cluster.hierarchy import ward, fcluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions <a class=\"anchor\" id=\"helper-functions\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to select data per time period\n",
    "def select_period(df, start_year, end_year, id):\n",
    "    new = df[(df.Year.astype(int) >= start_year) & (df.Year.astype(int) <= end_year)].copy()\n",
    "    new['ruleset'] = id\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to remove query string from url e.g. https://some.domain.com/page?querystring\n",
    "def remove_query_string(url):\n",
    "    # Parse the URL into its components\n",
    "    parsed_url = urlparse(url)\n",
    "\n",
    "    # Create a modified version of the parsed URL without the query string\n",
    "    modified_url = parsed_url._replace(query='')\n",
    "\n",
    "    # Convert the modified URL back to a string\n",
    "    cleaned_url = urlunparse(modified_url)\n",
    "\n",
    "    return cleaned_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to determine if string url contains specific file extensions - therefore is file not page\n",
    "def contains_substring(text):\n",
    "    substrings = [\".pdf\", \".xls\", \".doc\"]\n",
    "    for substring in substrings:\n",
    "        if substring in text:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to determine if the url is allowed according to given valid host list\n",
    "def allow_url(url, allowed_hosts):\n",
    "    hosts = allowed_hosts.split(\",\")\n",
    "    allowed = False\n",
    "\n",
    "    #for loop to iterate over words array\n",
    "    #print(\"Allow URL: \" + url)\n",
    "    for host in hosts:\n",
    "        #print(\"Allow Host: \" + host)\n",
    "        if url.startswith(host) or url.startswith(\"/\"):\n",
    "            allowed = True\n",
    "    # print(allowed)\n",
    "    return allowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_scrape_line(text, indent_level):\n",
    "\n",
    "    # Define the ANSI escape codes for different colors\n",
    "    YELLOW = '\\033[33m'\n",
    "    WHITE = '\\033[37m'\n",
    "\n",
    "    indent_size = 2\n",
    "    indent = \" \"\n",
    "    if indent_level > 0:\n",
    "        indent = \" \" * (1 + (indent_level * indent_size))\n",
    "\n",
    "    if text != \"STOP\":\n",
    "        current_time = datetime.datetime.now().strftime(\"%y-%m-%d %H:%M:%S\")\n",
    "        line = f\"{WHITE}{current_time}{indent}{YELLOW}{text}\"\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls_webscrape(website_url, allowed_hosts):\n",
    "    visited_urls = []\n",
    "    starting_url = website_url\n",
    "    starting_path = urlparse(starting_url).path\n",
    "    crawl(starting_url, visited_urls, \"\", starting_path, allowed_hosts)\n",
    "    return visited_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if debug: print(\"cleaning: \" + text)\n",
    "    # Remove unwanted characters\n",
    "    #text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    #text = text.lower()\n",
    "    # Normalize white space\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    text = text.strip()\n",
    "    # Convert the text to ASCII and remove diacritical marks\n",
    "    text = unicodedata.normalize(\"NFKD\", text).encode(\"ascii\", \"ignore\").decode(\"utf-8\")\n",
    "    # print(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_url(url):\n",
    "    \n",
    "    # Make a GET request to the URL\n",
    "    response = requests.get(url, headers = {'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36'}, timeout = 30)\n",
    "  \n",
    "    # Check if the response is successful\n",
    "    if response.status_code != 200:\n",
    "        return None\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    # Extract the text from the HTML content\n",
    "    text = \" \".join(text.strip() for text in soup.stripped_strings)\n",
    "    cleaned_text = clean_text(text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_style(tag):\n",
    "\treturn tag.has_attr('style')\n",
    "\n",
    "def has_class(tag):\n",
    "\treturn tag.has_attr('class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A soup cleaning function to remove empty tags\n",
    "def clean(soup):\n",
    "    if soup.name == 'br' or soup.name == 'img' or soup.name == 'p' or soup.name == 'div':\n",
    "        return\n",
    "    try:\n",
    "        ll = 0\n",
    "        for j in soup.strings:\n",
    "            ll += len(j.replace('\\n', ''))\n",
    "        if ll == 0:\n",
    "            if debug: print(\"decomposing\")\n",
    "            if isinstance(soup, Tag):\n",
    "                soup.decompose()\n",
    "        else:\n",
    "            for child in soup.children:\n",
    "                clean(child)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfs(soup, v):\n",
    "    if soup.name == 'a' or soup.name == 'br':\n",
    "        return\n",
    "    try:\n",
    "\n",
    "        lt = len(soup.get_text())\n",
    "        ls = len(str(soup))\n",
    "\n",
    "        if isinstance(soup, Tag):\n",
    "            a = soup.find_all('a')\n",
    "        else:\n",
    "            a = []\n",
    "        \n",
    "        at = 0\n",
    "\n",
    "        for j in a:\n",
    "            at += len(j.get_text())\n",
    "        lvt = lt - at\n",
    "        v.append((soup, lt / ls * lvt))\n",
    "\n",
    "        if isinstance(soup, Tag):\n",
    "            for child in soup.children:\n",
    "                dfs(child, v)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(soup, text_only = True, remove_img = True):\n",
    "\n",
    "    filt = ['script', 'noscript', 'style', 'embed', 'label', 'form', 'input', 'iframe', 'head', 'meta', 'link', 'object', 'aside', 'channel']\n",
    "\n",
    "    if (remove_img):\n",
    "        filt.append('img')\n",
    "\n",
    "    for ff in filt:\n",
    "        for i in soup.find_all(ff):\n",
    "            if isinstance(i, Tag):\n",
    "                i.decompose()\n",
    "\n",
    "    for tag in soup.find_all(has_style):\n",
    "        del tag['style']\n",
    "    for tag in soup.find_all(has_class):\n",
    "        del tag['class']\n",
    "\n",
    "    trimmed_text = soup.get_text().strip()\n",
    "    if (trimmed_text == \"\"):\n",
    "        print (\"empty empty\")\n",
    "        return \"\", 0\n",
    "\n",
    "    clean(soup)\n",
    "\n",
    "    LVT = len(soup.get_text())\n",
    "    for i in soup.find_all('a'):\n",
    "        LVT -= len(i.get_text())\n",
    "    v = []\n",
    "\n",
    "    dfs(soup, v)\n",
    "\n",
    "    mij = 0\n",
    "\n",
    "    # print(v)\n",
    "    for i in range(len(v)):\n",
    "        if v[i][1] > v[mij][1]:\n",
    "            mij = i\n",
    "\n",
    "    if text_only:\n",
    "        res = v[mij][0].get_text()\n",
    "    else:\n",
    "        res = str(v[mij][0])\n",
    "\n",
    "    return res, v[mij][1] / LVT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_list_get (l, idx, default):\n",
    "    try:\n",
    "        return l[idx]\n",
    "    except IndexError:\n",
    "        return default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl(url, visited_urls, base_url, starting_path, allowed_hosts):\n",
    "    if debug: print(\"crawl()\")\n",
    "    # Parse the URL to extract the base URL and path\n",
    "    parsed_url = urlparse(url)\n",
    "    base_url = \"{0.scheme}://{0.netloc}\".format(parsed_url)\n",
    "    path = parsed_url.path\n",
    "\n",
    "    if (remove_query_string(url) in visited_urls) or (((starting_path not in url) or (not path.startswith(starting_path))) and (allow_url(url, allowed_hosts) == False)):\n",
    "        # print(\"Exit\")\n",
    "        return\n",
    "\n",
    "    if (not \"mailto\" in url) and (not \"&url=\" in url):\n",
    "        url2 = url\n",
    "        if len(starting_path) > 1:\n",
    "            write_scrape_line(\"Found Page: \" + url2.replace(starting_path, \"/../\"), 2)\n",
    "        else:\n",
    "            write_scrape_line(\"Found Page: \" + url2, 2)\n",
    "     \n",
    "    # time.sleep(.2)\n",
    "    # Make a GET request to the URL\n",
    "    response = requests.get(url, headers = {'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36'}, timeout = 30)\n",
    "    # Check if the response is successful\n",
    "    # print(response.status_code)\n",
    "    if response.status_code != 200:\n",
    "        return\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    # Find all the links in the HTML content\n",
    "    links = [link.get(\"href\") for link in soup.find_all(\"a\")]\n",
    "    \n",
    "    # Add the URL to the visited URLs\n",
    "    visited_urls.append(remove_query_string(url))\n",
    "\n",
    "    # Recursively crawl the links that contain the base URL\n",
    "    for link in links:\n",
    "        try:\n",
    "            if (not contains_substring(link)):   \n",
    "                full_url = urljoin(base_url, link)\n",
    "                if debug: print(\"URL: \" + full_url)\n",
    "                if (link.startswith(starting_path) or link.startswith(url) or allow_url(full_url, allowed_hosts)) and full_url not in visited_urls:\n",
    "                    if debug: print(\"crawling\")\n",
    "                    crawl(full_url, visited_urls, base_url, starting_path, allowed_hosts)\n",
    "                # else:\n",
    "                    # print(\"Discarding URL: \" + full_url)\n",
    "        except:\n",
    "            exy = \"link\"\n",
    "            print(\"Link null in WebScraperHelper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_webscrape(urls, inner=''):\n",
    "    text = \"\"\n",
    "    total = len(urls)\n",
    "    counter = 0\n",
    "    for url in urls:\n",
    "        print(url)\n",
    "        # Make a GET request to the URL\n",
    "        response = requests.get(url, headers = {'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36'}, timeout = 30)\n",
    "        # Check if the response is successful\n",
    "        if debug: print(response.status_code)\n",
    "        if response.status_code != 200:\n",
    "            continue\n",
    "        # Parse the HTML content      \n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        try:\n",
    "            if inner != '':\n",
    "               soup = soup.find(inner)\n",
    "            extracted = extract(soup)\n",
    "            l = safe_list_get(extracted, 0, \"\")\n",
    "            text = clean_text(l)\n",
    "        except Exception as err:\n",
    "            print(\"error\")\n",
    "            text = \"\"\n",
    "            return \"\"\n",
    "        # return text #REMOVE THIS\n",
    "    return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_term_frequencies_ordered(strings):\n",
    "    \"\"\"\n",
    "    Given an array of strings, return a list of (term, frequency) pairs,\n",
    "    ordered by frequency in descending order.\n",
    "\n",
    "    :param strings: list of strings\n",
    "    :return: list of tuples (term, frequency) sorted in descending frequency\n",
    "    \"\"\"\n",
    "    freq_counter = Counter()\n",
    "\n",
    "    # Iterate over each string in the input\n",
    "    for s in strings:\n",
    "        # Tokenize by splitting on whitespace (you could also lowercase if desired)\n",
    "        tokens = s.split()\n",
    "        freq_counter.update(tokens)\n",
    "\n",
    "    # Sort by frequency (descending)\n",
    "    term_freq_list = sorted(freq_counter.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return term_freq_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdf_links_webscrape(keyword, pages):\n",
    "    # Initialize an empty list to store the PDF links\n",
    "    pdf_links = []\n",
    "    \n",
    "    # Initialize the starting index\n",
    "    start = 0\n",
    "    counter = 0\n",
    "    # Iterate over the specified number of pages\n",
    "    for i in range(pages):\n",
    "        counter = start\n",
    "\n",
    "        # Build the URL with the keyword and starting index\n",
    "        url = f\"https://arxiv.org/search/?searchtype=all&query={keyword}&abstracts=show&size=50&order=-announced_date_first&start={start}\"\n",
    "        \n",
    "        # Make a GET request to the URL\n",
    "        response = requests.get(url, headers = {'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36'}, timeout = 30)\n",
    "        \n",
    "        # Check if the response is successful\n",
    "        if response.status_code != 200:\n",
    "            break\n",
    "        \n",
    "        # Parse the HTML content\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        \n",
    "        # Find all the <li> items with class \"arxiv-result\"\n",
    "        li_items = soup.find_all(\"li\", class_=\"arxiv-result\")\n",
    "        \n",
    "        # Iterate over the <li> items\n",
    "        for li in li_items:\n",
    "            \n",
    "            # Find the first <a> tag with the text \"pdf\"\n",
    "            a_tag = li.find(\"a\", text=\"pdf\")\n",
    "            \n",
    "            # Check if the <a> tag was found\n",
    "            if a_tag:\n",
    "                # Get the href attribute of the <a> tag\n",
    "                pdf_link = a_tag.get(\"href\")\n",
    "                \n",
    "                # Add the PDF link to the list\n",
    "                pdf_links.append(pdf_link + \".pdf\")\n",
    "            \n",
    "            # Logging code \n",
    "            counter += 1    \n",
    "            log(\"B\", \"1\", counter, (pages * 50), \"collecting academia...\")\n",
    "            time.sleep(.1)\n",
    "        \n",
    "\n",
    "        # Increment the starting index\n",
    "        start += 50\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    return pdf_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample - Denmark <a class=\"anchor\" id=\"sample-usecase\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following is a working example of one of the country sets contained in this piece of work. Note, due to the distributed nature of the data mining platform used in the research, this sample code does not contain all of the features including extracting pdf text content found in links on the crawled webpages. Please be aware this will change the results significantly as will updates made on the website over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m24-12-23 20:09:07     \u001b[33mFound Page: https://en.digst.dk/../\n",
      "\u001b[37m24-12-23 20:09:09     \u001b[33mFound Page: https://en.digst.dk/policy/international-cooperation/\n",
      "\u001b[37m24-12-23 20:09:10     \u001b[33mFound Page: https://en.digst.dk/strategy/\n",
      "\u001b[37m24-12-23 20:09:11     \u001b[33mFound Page: https://en.digst.dk/strategy/the-national-strategy-for-digitalisation/\n",
      "\u001b[37m24-12-23 20:09:12     \u001b[33mFound Page: https://en.digst.dk/strategy/the-joint-government-digital-strategy/\n",
      "\u001b[37m24-12-23 20:09:14     \u001b[33mFound Page: https://en.digst.dk/strategy/the-danish-national-strategy-for-cyber-and-information-security/\n",
      "\u001b[37m24-12-23 20:09:15     \u001b[33mFound Page: https://en.digst.dk/strategy/the-danish-national-strategy-for-artificial-intelligence/\n",
      "\u001b[37m24-12-23 20:09:16     \u001b[33mFound Page: https://en.digst.dk/policy/\n",
      "\u001b[37m24-12-23 20:09:18     \u001b[33mFound Page: https://en.digst.dk/policy/the-danish-digital-journey/\n",
      "\u001b[37m24-12-23 20:09:19     \u001b[33mFound Page: https://en.digst.dk/policy/government-digital-academy/\n",
      "\u001b[37m24-12-23 20:09:20     \u001b[33mFound Page: https://en.digst.dk/digital-governance/\n",
      "\u001b[37m24-12-23 20:09:21     \u001b[33mFound Page: https://en.digst.dk/digital-governance/digital-architecture/\n",
      "\u001b[37m24-12-23 20:09:22     \u001b[33mFound Page: https://en.digst.dk/digital-governance/data/\n",
      "\u001b[37m24-12-23 20:09:24     \u001b[33mFound Page: https://en.digst.dk/digital-governance/information-security-in-danish-authorities/\n",
      "\u001b[37m24-12-23 20:09:25     \u001b[33mFound Page: https://en.digst.dk/digital-governance/data-ethics-in-business/\n",
      "\u001b[37m24-12-23 20:09:26     \u001b[33mFound Page: https://en.digst.dk/digital-governance/new-technologies/\n",
      "\u001b[37m24-12-23 20:09:28     \u001b[33mFound Page: https://en.digst.dk/digital-services/\n",
      "\u001b[37m24-12-23 20:09:29     \u001b[33mFound Page: https://en.digst.dk/digital-services/borgerdk-national-citizen-portal/\n",
      "\u001b[37m24-12-23 20:09:30     \u001b[33mFound Page: https://en.digst.dk/digital-services/digital-inclusion/\n",
      "\u001b[37m24-12-23 20:09:31     \u001b[33mFound Page: https://en.digst.dk/digital-services/eid-and-digital-self-services-across-the-eueea/\n",
      "\u001b[37m24-12-23 20:09:32     \u001b[33mFound Page: https://en.digst.dk/digital-services/web-accessibility-in-denmark/\n",
      "\u001b[37m24-12-23 20:09:34     \u001b[33mFound Page: https://en.digst.dk/systems/\n",
      "\u001b[37m24-12-23 20:09:35     \u001b[33mFound Page: https://en.digst.dk/systems/mitid-erhverv/\n",
      "\u001b[37m24-12-23 20:09:36     \u001b[33mFound Page: https://en.digst.dk/systems/digital-post/\n",
      "\u001b[37m24-12-23 20:09:38     \u001b[33mFound Page: https://en.digst.dk/systems/nemlog-in/\n",
      "\u001b[37m24-12-23 20:09:39     \u001b[33mFound Page: https://en.digst.dk/systems/nemkonto/\n",
      "\u001b[37m24-12-23 20:09:40     \u001b[33mFound Page: https://en.digst.dk/systems/driving-licence-app/\n",
      "\u001b[37m24-12-23 20:09:41     \u001b[33mFound Page: https://en.digst.dk/systems/health-insurance-card-app/\n",
      "\u001b[37m24-12-23 20:09:42     \u001b[33mFound Page: https://en.digst.dk/systems/digital-post-app/\n",
      "\u001b[37m24-12-23 20:09:44     \u001b[33mFound Page: https://en.digst.dk/systems/single-digital-gateway-regulation/\n",
      "\u001b[37m24-12-23 20:09:45     \u001b[33mFound Page: https://en.digst.dk/systems/health-insurance-card-app/background/\n",
      "\u001b[37m24-12-23 20:09:46     \u001b[33mFound Page: https://en.digst.dk/systems/health-insurance-card-app/security/\n",
      "\u001b[37m24-12-23 20:09:48     \u001b[33mFound Page: https://en.digst.dk/systems/health-insurance-card-app/terms-and-conditions/\n",
      "\u001b[37m24-12-23 20:09:49     \u001b[33mFound Page: https://en.digst.dk/systems/driving-licence-app/background/\n",
      "\u001b[37m24-12-23 20:09:50     \u001b[33mFound Page: https://en.digst.dk/systems/driving-licence-app/security/\n",
      "\u001b[37m24-12-23 20:09:52     \u001b[33mFound Page: https://en.digst.dk/systems/nemlog-in/nemlog-in-components/\n",
      "\u001b[37m24-12-23 20:09:53     \u001b[33mFound Page: https://en.digst.dk/systems/nemlog-in/terms-and-security/\n",
      "\u001b[37m24-12-23 20:09:54     \u001b[33mFound Page: https://en.digst.dk/systems/digital-post/about-the-national-digital-post/\n",
      "\u001b[37m24-12-23 20:09:56     \u001b[33mFound Page: https://en.digst.dk/systems/digital-post/about-the-national-digital-post/suppliers-of-digital-post/\n",
      "\u001b[37m24-12-23 20:09:57     \u001b[33mFound Page: https://en.digst.dk/systems/digital-post/about-the-national-digital-post/notifications-about-digital-post/\n",
      "\u001b[37m24-12-23 20:09:58     \u001b[33mFound Page: https://en.digst.dk/systems/digital-post/about-the-national-digital-post/background/\n",
      "\u001b[37m24-12-23 20:09:59     \u001b[33mFound Page: https://en.digst.dk/systems/digital-post/current-legislation-about-digital-post/\n",
      "\u001b[37m24-12-23 20:10:01     \u001b[33mFound Page: https://en.digst.dk/systems/digital-post/digital-post-user-data/\n",
      "\u001b[37m24-12-23 20:10:02     \u001b[33mFound Page: https://en.digst.dk/systems/digital-post/nemsms\n",
      "\u001b[37m24-12-23 20:10:04     \u001b[33mFound Page: https://en.digst.dk/systems/digital-post/nemsms\n",
      "\u001b[37m24-12-23 20:10:05     \u001b[33mFound Page: https://en.digst.dk/systems/digital-post/nemsms\n",
      "\u001b[37m24-12-23 20:10:07     \u001b[33mFound Page: https://en.digst.dk/systems/digital-post/nemsms\n",
      "\u001b[37m24-12-23 20:10:09     \u001b[33mFound Page: https://en.digst.dk/systems/digital-post/nemsms\n",
      "\u001b[37m24-12-23 20:10:11     \u001b[33mFound Page: https://en.digst.dk/systems/digital-post/nemsms\n",
      "\u001b[37m24-12-23 20:10:13     \u001b[33mFound Page: https://en.digst.dk/systems/digital-post/nemsms\n",
      "\u001b[37m24-12-23 20:10:15     \u001b[33mFound Page: https://en.digst.dk/systems/digital-post/nemsms\n",
      "\u001b[37m24-12-23 20:10:16     \u001b[33mFound Page: https://en.digst.dk/digital-services/web-accessibility-in-denmark/monitoring-and-supervision/\n",
      "\u001b[37m24-12-23 20:10:18     \u001b[33mFound Page: https://en.digst.dk/digital-services/eid-and-digital-self-services-across-the-eueea/using-digital-self-services-and-electronic-identification-across-the-eueea/\n",
      "\u001b[37m24-12-23 20:10:19     \u001b[33mFound Page: https://en.digst.dk/digital-services/eid-and-digital-self-services-across-the-eueea/use-your-nemidmitid-for-digital-self-service-in-the-eueea/\n",
      "\u001b[37m24-12-23 20:10:20     \u001b[33mFound Page: https://en.digst.dk/digital-services/eid-and-digital-self-services-across-the-eueea/use-danish-digital-self-services-with-a-non-danish-eid/\n",
      "\u001b[37m24-12-23 20:10:21     \u001b[33mFound Page: https://en.digst.dk/digital-services/eid-and-digital-self-services-across-the-eueea/information-for-danish-authorities/\n",
      "\u001b[37m24-12-23 20:10:23     \u001b[33mFound Page: https://en.digst.dk/digital-services/eid-and-digital-self-services-across-the-eueea/eid-gateway-notification-on-the-collection-of-personal-data-dk-connector/\n",
      "\u001b[37m24-12-23 20:10:24     \u001b[33mFound Page: https://en.digst.dk/digital-services/eid-and-digital-self-services-across-the-eueea/eid-gateway-notification-on-the-collection-of-personal-data-dk-service/\n",
      "\u001b[37m24-12-23 20:10:25     \u001b[33mFound Page: https://en.digst.dk/digital-services/borgerdk-national-citizen-portal/my-overview/\n",
      "\u001b[37m24-12-23 20:10:26     \u001b[33mFound Page: https://en.digst.dk/digital-services/borgerdk-national-citizen-portal/digital-post-on-borgerdk/\n",
      "\u001b[37m24-12-23 20:10:28     \u001b[33mFound Page: https://en.digst.dk/digital-services/borgerdk-national-citizen-portal/life-event-guides/\n",
      "\u001b[37m24-12-23 20:10:29     \u001b[33mFound Page: https://en.digst.dk/digital-services/borgerdk-national-citizen-portal/lifeindenmarkdk/\n",
      "\u001b[37m24-12-23 20:10:30     \u001b[33mFound Page: https://en.digst.dk/../mitid-a-unique-public-private-partnership/\n",
      "\u001b[37m24-12-23 20:10:32     \u001b[33mFound Page: https://en.digst.dk/digital-governance/new-technologies/a-common-danish-language-resource/\n",
      "\u001b[37m24-12-23 20:10:33     \u001b[33mFound Page: https://en.digst.dk/digital-governance/new-technologies/guide-on-the-use-of-cloud-services/\n",
      "\u001b[37m24-12-23 20:10:34     \u001b[33mFound Page: https://en.digst.dk/digital-governance/information-security-in-danish-authorities/operationalising-information-security/\n",
      "\u001b[37m24-12-23 20:10:36     \u001b[33mFound Page: https://en.digst.dk/digital-governance/information-security-in-danish-authorities/guidance-and-support/\n",
      "\u001b[37m24-12-23 20:10:37     \u001b[33mFound Page: https://en.digst.dk/digital-governance/data/open-data-and-re-use-of-public-sector-information/\n",
      "\u001b[37m24-12-23 20:10:38     \u001b[33mFound Page: https://en.digst.dk/digital-governance/data/the-danish-data-portal/\n",
      "\u001b[37m24-12-23 20:10:39     \u001b[33mFound Page: https://en.digst.dk/digital-governance/digital-architecture/white-paper-on-a-common-public-sector-digital-architecture/\n",
      "\u001b[37m24-12-23 20:10:41     \u001b[33mFound Page: https://en.digst.dk/strategy/the-danish-national-strategy-for-cyber-and-information-security/strategic-objectives/\n"
     ]
    }
   ],
   "source": [
    "website = \"https://en.digst.dk/systems/mitid/\"\n",
    "allowed_hosts = \"https://en.digst.dk/strategy/,https://en.digst.dk/policy/,https://en.digst.dk/digital-governance/,https://en.digst.dk/digital-services/,https://en.digst.dk/systems/,https://www.mitid.dk/en-gb/\"\n",
    "urls = get_urls_webscrape(website, allowed_hosts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://en.digst.dk/systems/mitid/', 'https://en.digst.dk/policy/international-cooperation/', 'https://en.digst.dk/strategy/', 'https://en.digst.dk/strategy/the-national-strategy-for-digitalisation/', 'https://en.digst.dk/strategy/the-joint-government-digital-strategy/', 'https://en.digst.dk/strategy/the-danish-national-strategy-for-cyber-and-information-security/', 'https://en.digst.dk/strategy/the-danish-national-strategy-for-artificial-intelligence/', 'https://en.digst.dk/policy/', 'https://en.digst.dk/policy/the-danish-digital-journey/', 'https://en.digst.dk/policy/government-digital-academy/', 'https://en.digst.dk/digital-governance/', 'https://en.digst.dk/digital-governance/digital-architecture/', 'https://en.digst.dk/digital-governance/data/', 'https://en.digst.dk/digital-governance/information-security-in-danish-authorities/', 'https://en.digst.dk/digital-governance/data-ethics-in-business/', 'https://en.digst.dk/digital-governance/new-technologies/', 'https://en.digst.dk/digital-services/', 'https://en.digst.dk/digital-services/borgerdk-national-citizen-portal/', 'https://en.digst.dk/digital-services/digital-inclusion/', 'https://en.digst.dk/digital-services/eid-and-digital-self-services-across-the-eueea/']\n"
     ]
    }
   ],
   "source": [
    "# Print the urls found while crawling the website\n",
    "print(urls[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://en.digst.dk/systems/mitid/\n",
      "https://en.digst.dk/policy/international-cooperation/\n",
      "https://en.digst.dk/strategy/\n",
      "https://en.digst.dk/strategy/the-national-strategy-for-digitalisation/\n",
      "https://en.digst.dk/strategy/the-joint-government-digital-strategy/\n",
      "https://en.digst.dk/strategy/the-danish-national-strategy-for-cyber-and-information-security/\n",
      "https://en.digst.dk/strategy/the-danish-national-strategy-for-artificial-intelligence/\n",
      "https://en.digst.dk/policy/\n",
      "https://en.digst.dk/policy/the-danish-digital-journey/\n",
      "https://en.digst.dk/policy/government-digital-academy/\n",
      "https://en.digst.dk/digital-governance/\n",
      "https://en.digst.dk/digital-governance/digital-architecture/\n",
      "https://en.digst.dk/digital-governance/data/\n",
      "https://en.digst.dk/digital-governance/information-security-in-danish-authorities/\n",
      "https://en.digst.dk/digital-governance/data-ethics-in-business/\n",
      "https://en.digst.dk/digital-governance/new-technologies/\n",
      "https://en.digst.dk/digital-services/\n",
      "https://en.digst.dk/digital-services/borgerdk-national-citizen-portal/\n",
      "https://en.digst.dk/digital-services/digital-inclusion/\n",
      "https://en.digst.dk/digital-services/eid-and-digital-self-services-across-the-eueea/\n",
      "https://en.digst.dk/digital-services/web-accessibility-in-denmark/\n",
      "https://en.digst.dk/systems/\n",
      "https://en.digst.dk/systems/mitid-erhverv/\n",
      "https://en.digst.dk/systems/digital-post/\n",
      "https://en.digst.dk/systems/nemlog-in/\n",
      "https://en.digst.dk/systems/nemkonto/\n",
      "https://en.digst.dk/systems/driving-licence-app/\n",
      "https://en.digst.dk/systems/health-insurance-card-app/\n",
      "https://en.digst.dk/systems/digital-post-app/\n",
      "https://en.digst.dk/systems/single-digital-gateway-regulation/\n",
      "https://en.digst.dk/systems/health-insurance-card-app/background/\n",
      "https://en.digst.dk/systems/health-insurance-card-app/security/\n",
      "https://en.digst.dk/systems/health-insurance-card-app/terms-and-conditions/\n",
      "https://en.digst.dk/systems/driving-licence-app/background/\n",
      "https://en.digst.dk/systems/driving-licence-app/security/\n",
      "https://en.digst.dk/systems/nemlog-in/nemlog-in-components/\n",
      "https://en.digst.dk/systems/nemlog-in/terms-and-security/\n",
      "https://en.digst.dk/systems/digital-post/about-the-national-digital-post/\n",
      "https://en.digst.dk/systems/digital-post/about-the-national-digital-post/suppliers-of-digital-post/\n",
      "https://en.digst.dk/systems/digital-post/about-the-national-digital-post/notifications-about-digital-post/\n",
      "https://en.digst.dk/systems/digital-post/about-the-national-digital-post/background/\n",
      "https://en.digst.dk/systems/digital-post/current-legislation-about-digital-post/\n",
      "https://en.digst.dk/systems/digital-post/digital-post-user-data/\n",
      "https://en.digst.dk/digital-services/web-accessibility-in-denmark/monitoring-and-supervision/\n",
      "https://en.digst.dk/digital-services/eid-and-digital-self-services-across-the-eueea/using-digital-self-services-and-electronic-identification-across-the-eueea/\n",
      "https://en.digst.dk/digital-services/eid-and-digital-self-services-across-the-eueea/use-your-nemidmitid-for-digital-self-service-in-the-eueea/\n",
      "https://en.digst.dk/digital-services/eid-and-digital-self-services-across-the-eueea/use-danish-digital-self-services-with-a-non-danish-eid/\n",
      "https://en.digst.dk/digital-services/eid-and-digital-self-services-across-the-eueea/information-for-danish-authorities/\n",
      "https://en.digst.dk/digital-services/eid-and-digital-self-services-across-the-eueea/eid-gateway-notification-on-the-collection-of-personal-data-dk-connector/\n",
      "https://en.digst.dk/digital-services/eid-and-digital-self-services-across-the-eueea/eid-gateway-notification-on-the-collection-of-personal-data-dk-service/\n",
      "https://en.digst.dk/digital-services/borgerdk-national-citizen-portal/my-overview/\n",
      "https://en.digst.dk/digital-services/borgerdk-national-citizen-portal/digital-post-on-borgerdk/\n",
      "https://en.digst.dk/digital-services/borgerdk-national-citizen-portal/life-event-guides/\n",
      "https://en.digst.dk/digital-services/borgerdk-national-citizen-portal/lifeindenmarkdk/\n",
      "https://en.digst.dk/digital-governance/new-technologies/a-common-danish-language-resource/\n",
      "https://en.digst.dk/digital-governance/new-technologies/guide-on-the-use-of-cloud-services/\n",
      "https://en.digst.dk/digital-governance/information-security-in-danish-authorities/operationalising-information-security/\n",
      "https://en.digst.dk/digital-governance/information-security-in-danish-authorities/guidance-and-support/\n",
      "https://en.digst.dk/digital-governance/data/open-data-and-re-use-of-public-sector-information/\n",
      "https://en.digst.dk/digital-governance/data/the-danish-data-portal/\n",
      "https://en.digst.dk/digital-governance/digital-architecture/white-paper-on-a-common-public-sector-digital-architecture/\n",
      "https://en.digst.dk/strategy/the-danish-national-strategy-for-cyber-and-information-security/strategic-objectives/\n"
     ]
    }
   ],
   "source": [
    "text = []\n",
    "for url in urls:\n",
    "    text.append(get_text_webscrape([url], 'main'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"MitID MitID (the Danish National eID) is Denmark's digital ID that residents will use to access their public self-service solutions. eID is the key to digital Denmark. Today, more than 90 percent of the population uses their national eID in situations where it is essential to document ones identity electronically. eID enhances the scope of communication between residents and the public sector, and helps the public sector to offer better services to residents and businesses. It allows for residents to access their public services 24 hours a day. The switch to digital-first was enabled by the rollout of Denmarks second-generation national eID (NemID) in 2010. This served as a communal login for public and private self-service solutions and online banking. Digital solutions are renewed or replaced over time. That happens because of security requirements and new technology. In 2022 Denmark's third generation eID, MitID, was introduced. This new eID satisfies the latest security requirements, meaning that we can use the internet with confidence now and in future. MitID is the result of a well-established and unique collaboration between the public sector and the banks, and is a shared solution across businesses, persons, and authorities. Read more about eID in Denmark\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_sentences(text: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Takes a text string as input and returns a list of sentence strings, all in lowercase.\n",
    "    \"\"\"\n",
    "    # Convert the text to lowercase\n",
    "    lowercase_text = text.lower().strip()\n",
    "    \n",
    "    # Split the text into sentences by ., ?, or !\n",
    "    potential_sentences = re.split(r'[.?!]+', lowercase_text)\n",
    "    \n",
    "    # Strip whitespace from each sentence and filter out empty ones\n",
    "    sentences = [sentence.strip() for sentence in potential_sentences if sentence.strip()]\n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = []\n",
    "for page in text:\n",
    "    chunks = chunks + text_to_sentences(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"mitid mitid (the danish national eid) is denmark's digital id that residents will use to access their public self-service solutions\", 'eid is the key to digital denmark', 'today, more than 90 percent of the population uses their national eid in situations where it is essential to document ones identity electronically', 'eid enhances the scope of communication between residents and the public sector, and helps the public sector to offer better services to residents and businesses', 'it allows for residents to access their public services 24 hours a day']\n"
     ]
    }
   ],
   "source": [
    "print(chunks[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def extract_lemmatized_nouns(sentences):\n",
    "    \"\"\"\n",
    "    Takes a list of sentences (strings) as input and returns a list of strings,\n",
    "    where each output string contains only the lemmatized nouns from the corresponding input sentence.\n",
    "    \"\"\"\n",
    "\n",
    "    def get_wordnet_pos(pos_tag):\n",
    "        \"\"\"\n",
    "        Convert the part-of-speech tag from NLTK's 'pos_tag' to a format\n",
    "        that the WordNetLemmatizer can understand (e.g., wordnet.NOUN).\n",
    "        \"\"\"\n",
    "        if pos_tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif pos_tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif pos_tag.startswith('N'):\n",
    "            return wordnet.NOUN\n",
    "        elif pos_tag.startswith('R'):\n",
    "            return wordnet.ADV\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    noun_sentences = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        # Tokenize the sentence\n",
    "        tokens = word_tokenize(sentence)\n",
    "\n",
    "        # Get the POS tags for each token\n",
    "        pos_tags = nltk.pos_tag(tokens)\n",
    "\n",
    "        # Collect only lemmatized nouns\n",
    "        lemmatized_nouns = []\n",
    "        for (word, tag) in pos_tags:\n",
    "            wordnet_pos = get_wordnet_pos(tag)\n",
    "            # Check if it's a noun\n",
    "            if wordnet_pos == wordnet.NOUN:\n",
    "                # Lemmatize the noun (lowercase to keep consistent)\n",
    "                lemma = lemmatizer.lemmatize(word.lower(), pos=wordnet_pos)\n",
    "                lemmatized_nouns.append(lemma)\n",
    "        \n",
    "        # Join the lemmatized nouns into a single string\n",
    "        noun_sentences.append(\" \".join(lemmatized_nouns))\n",
    "\n",
    "    return noun_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mitid mitid eid denmark id resident access solution', 'eid key denmark', 'today percent population eid situation one identity', 'eid scope communication resident public sector public sector service resident business', 'resident access service hour day']\n"
     ]
    }
   ],
   "source": [
    "lemmings = extract_lemmatized_nouns(chunks)\n",
    "print(lemmings[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Metrics <a class=\"anchor\" id=\"term-metrics\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('data', 268), ('government', 174), ('authority', 147), ('post', 137), ('sector', 129), ('information', 128), ('app', 125), ('denmark', 113), ('agency', 110), ('service', 100), ('dk', 100), ('business', 86), ('citizen', 84), ('public', 82), ('strategy', 79), ('security', 72), ('health', 68), ('right', 68), ('number', 66), ('card', 66)]\n"
     ]
    }
   ],
   "source": [
    "freq = get_term_frequencies_ordered(lemmings)\n",
    "print(freq[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering <a class=\"anchor\" id=\"clustering\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA 4 clustering routines----------------------------------------\n",
    "# Global variables\n",
    "global_topic_keywords_lda = []\n",
    "global_count_matrix_lda = None\n",
    "global_vectorizer_lda = None\n",
    "global_lda_model_lda = None\n",
    "\n",
    "def cluster_sentences_lda(sentences, n_topics=5, num_keywords=3):\n",
    "    global global_topic_keywords_lda, global_count_matrix_lda, global_vectorizer_lda, global_lda_model_lda\n",
    "    global_topic_keywords_lda = []\n",
    "    global_vectorizer_lda = CountVectorizer(stop_words='english')\n",
    "    global_count_matrix_lda = global_vectorizer_lda.fit_transform(sentences)\n",
    "\n",
    "    global_lda_model_lda = LatentDirichletAllocation(n_components=n_topics, random_state=42)\n",
    "    global_lda_model_lda.fit(global_count_matrix_lda)\n",
    "\n",
    "    keywords = []\n",
    "    terms = global_vectorizer_lda.get_feature_names_out()\n",
    "    for topic_idx, topic in enumerate(global_lda_model_lda.components_):\n",
    "        keywords = [terms[i] for i in topic.argsort()[-num_keywords:][::-1]]\n",
    "        global_topic_keywords_lda.append(keywords)\n",
    "\n",
    "    return global_topic_keywords_lda\n",
    "\n",
    "def find_cluster_for_sentence_lda(sentence):\n",
    "    global global_lda_model_lda, global_vectorizer_lda\n",
    "\n",
    "    if global_lda_model_lda is None or not global_vectorizer_lda:\n",
    "        return None, None\n",
    "\n",
    "    sentence_vector = global_vectorizer_lda.transform([sentence])\n",
    "    topic_distribution = global_lda_model_lda.transform(sentence_vector)\n",
    "    most_likely_topic = topic_distribution[0].argmax()\n",
    "\n",
    "    # Using the max probability for the topic as similarity\n",
    "    similarity = topic_distribution[0][most_likely_topic]\n",
    "\n",
    "    arr_str = []\n",
    "    arr_str.append(str(most_likely_topic))\n",
    "    arr_str.append(str(similarity))\n",
    "    return arr_str\n",
    "\n",
    "def nlp_preprocess_lda_file(num_clusters, num_keywords, file_path):\n",
    "    # Example Usage:\n",
    "    sample_texts = []\n",
    "\n",
    "    # Open the file for reading\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file: \n",
    "        # Read each line and append it to the 'lines' list\n",
    "        for line in file:\n",
    "            text = unicodedata.normalize(\"NFKD\", line).encode(\"ascii\", \"ignore\").decode(\"utf-8\")\n",
    "            sample_texts.append(text.strip())  # Use strip() to remove newline characters\n",
    "\n",
    "    global_cluster_keywords_lda = []\n",
    "    global_cluster_keywords_lda = cluster_sentences_lda(sample_texts, num_clusters, num_keywords)\n",
    "\n",
    "    str_arr = []\n",
    "    for cluster in global_cluster_keywords_lda:\n",
    "        str_arr.append(str(cluster))        \n",
    "    return str_arr\n",
    "\n",
    "def nlp_preprocess_lda(num_clusters, num_keywords, string_array):\n",
    "    # Example Usage:\n",
    "    sample_texts = []\n",
    "    \n",
    "    # Process each string in the input array\n",
    "    for line in string_array:\n",
    "        # Normalize and remove non-ASCII characters\n",
    "        text = unicodedata.normalize(\"NFKD\", line).encode(\"ascii\", \"ignore\").decode(\"utf-8\")\n",
    "        sample_texts.append(text.strip())\n",
    "\n",
    "    # Call your clustering function (not provided in this code snippet)\n",
    "    global_cluster_keywords_lda = cluster_sentences_lda(sample_texts, num_clusters, num_keywords)\n",
    "\n",
    "    # Convert each cluster's keywords to a string\n",
    "    str_arr = []\n",
    "    for cluster in global_cluster_keywords_lda:\n",
    "        str_arr.append(str(cluster))\n",
    "\n",
    "    return str_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"['data', 'right', 'protection', 'processing', 'information', 'agency', 'case', 'digst', 'number', 'authority']\", \"['data', 'service', 'eid', 'self', 'company', 'country', 'eu', 'gateway', 'ethic', 'mitid']\", \"['post', 'dk', 'authority', 'citizen', 'business', 'borger', 'resident', 'sector', 'people', 'solution']\", \"['app', 'health', 'card', 'insurance', 'number', 'phone', 'information', 'licence', 'lifeindenmark', 'user']\", \"['government', 'sector', 'agency', 'strategy', 'security', 'denmark', 'public', 'information', 'service', 'authority']\"]\n"
     ]
    }
   ],
   "source": [
    "clusters = nlp_preprocess_lda(5, 10, lemmings)\n",
    "print(clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF Routines<a class=\"anchor\" id=\"pdf-routines\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_pdf_links(url):\n",
    "    pdf_links = []\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers = {'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36'}, timeout = 30)\n",
    "  \n",
    "        response.raise_for_status()  # Check for request errors\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        for link in soup.find_all('a', href=True):\n",
    "            href = link['href']\n",
    "            if re.search(r'\\.pdf$', href, re.I):\n",
    "                if href.startswith('http') or href.startswith('www'):\n",
    "                    pdf_links.append(href)\n",
    "                else:\n",
    "                    parsed_url = urlparse(url)\n",
    "                    base_url = \"{0.scheme}://{0.netloc}\".format(parsed_url)\n",
    "                    pdf_links.append(base_url + href)\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    return pdf_links\n",
    "\n",
    "def get_text_webscrape2(urls):\n",
    "\n",
    "    text = \"\"\n",
    "    total = len(urls)\n",
    "    counter = 0\n",
    "    for url in urls:\n",
    "\n",
    "        # Make a GET request to the URL\n",
    "        response = requests.get(url, headers = {'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36'}, timeout = 30)\n",
    "          \n",
    "        # Check if the response is successful\n",
    "        if response.status_code != 200:\n",
    "            continue\n",
    "        \n",
    "        # Parse the HTML content\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        \n",
    "        # Extract the text from the HTML content\n",
    "        page_text = soup.get_text()\n",
    "        \n",
    "        # Add the text to the overall text\n",
    "        text += page_text\n",
    "\n",
    "        # Log code\n",
    "        counter += 1\n",
    "        log(\"C\", \"1\", counter, total, \"scraping text...\")\n",
    "        time.sleep(.2)\n",
    "        \n",
    "    \n",
    "    cleaned_text = clean_text(text)\n",
    "    \n",
    "    # print(cleaned_text)\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "\n",
    "def get_pdf_links_webscrape(keyword, pages):\n",
    "    # Initialize an empty list to store the PDF links\n",
    "    pdf_links = []\n",
    "    \n",
    "    # Initialize the starting index\n",
    "    start = 0\n",
    "    counter = 0\n",
    "    # Iterate over the specified number of pages\n",
    "    for i in range(pages):\n",
    "        counter = start\n",
    "\n",
    "        # Build the URL with the keyword and starting index\n",
    "        url = f\"https://arxiv.org/search/?searchtype=all&query={keyword}&abstracts=show&size=50&order=-announced_date_first&start={start}\"\n",
    "        \n",
    "        # Make a GET request to the URL\n",
    "        response = requests.get(url, headers = {'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36'}, timeout = 30)\n",
    "        \n",
    "        # Check if the response is successful\n",
    "        if response.status_code != 200:\n",
    "            break\n",
    "        \n",
    "        # Parse the HTML content\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        \n",
    "        # Find all the <li> items with class \"arxiv-result\"\n",
    "        li_items = soup.find_all(\"li\", class_=\"arxiv-result\")\n",
    "        \n",
    "        # Iterate over the <li> items\n",
    "        for li in li_items:\n",
    "            \n",
    "            # Find the first <a> tag with the text \"pdf\"\n",
    "            a_tag = li.find(\"a\", text=\"pdf\")\n",
    "            \n",
    "            # Check if the <a> tag was found\n",
    "            if a_tag:\n",
    "                # Get the href attribute of the <a> tag\n",
    "                pdf_link = a_tag.get(\"href\")\n",
    "                \n",
    "                # Add the PDF link to the list\n",
    "                pdf_links.append(pdf_link + \".pdf\")\n",
    "            \n",
    "            # Logging code \n",
    "            counter += 1    \n",
    "            log(\"B\", \"1\", counter, (pages * 50), \"collecting academia...\")\n",
    "            time.sleep(.1)\n",
    "        \n",
    "\n",
    "        # Increment the starting index\n",
    "        start += 50\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    return pdf_links\n",
    "\n",
    "\n",
    "\n",
    "def download_pdf(pdf_url, label):\n",
    "    time.sleep(.2)\n",
    "    folder = \"./Files/Downloads/\"+ label + \"/\";\n",
    "\n",
    "    # Check whether the specified path exists or not\n",
    "    isExist = os.path.exists(folder)\n",
    "    if not isExist:\n",
    "        # Create a new directory because it does not exist\n",
    "        os.makedirs(folder)\n",
    "\n",
    "\n",
    "    # Extract the file name from the URL\n",
    "    file_name = pdf_url.split(\"/\")[-1]\n",
    "    \n",
    "    # Build the full file path\n",
    "    file_path = os.path.join(folder, file_name)\n",
    "\n",
    "\n",
    "    if os.path.isfile(file_path) == False:\n",
    "        # Make a GET request to the URL\n",
    "        response = requests.get(pdf_url, headers = {'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36'}, timeout = 30)\n",
    "     \n",
    "        # Check if the response is successful\n",
    "        if response.status_code != 200:\n",
    "            return\n",
    "    \n",
    "        # Write the content to the file\n",
    "        with open(file_path, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Code<a class=\"anchor\" id=\"residual-code\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'Access-Control-Allow-Origin': '*',\n",
    "    'Access-Control-Allow-Methods': 'GET',\n",
    "    'Access-Control-Allow-Headers': 'Content-Type',\n",
    "    'Access-Control-Max-Age': '3600',\n",
    "    'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Scrape metadata from target URL.\"\"\"\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pprint\n",
    "import urllib\n",
    "\n",
    "def get_download_url(url):\n",
    "    \"\"\"Scrape target URL for metadata.\"\"\"\n",
    "    headers = {\n",
    "        'Access-Control-Allow-Origin': '*',\n",
    "        'Access-Control-Allow-Methods': 'GET',\n",
    "        'Access-Control-Allow-Headers': 'Content-Type',\n",
    "        'Access-Control-Max-Age': '3600',\n",
    "        'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0'\n",
    "    }\n",
    "    \n",
    "    r = requests.get(url, headers=headers)\n",
    "    html = BeautifulSoup(r.content, 'html.parser')\n",
    "    print(html)\n",
    "    return get_pdf(html)\n",
    "    \n",
    "def download_file(url, filename):\n",
    "    urllib.urlretrieve (\"http://www.example.com/songs/mp3.mp3\", \"mp3.mp3\")\n",
    "\n",
    "def scrape_page_metadata(url):\n",
    "    \"\"\"Scrape target URL for metadata.\"\"\"\n",
    "    headers = {\n",
    "        'Access-Control-Allow-Origin': '*',\n",
    "        'Access-Control-Allow-Methods': 'GET',\n",
    "        'Access-Control-Allow-Headers': 'Content-Type',\n",
    "        'Access-Control-Max-Age': '3600',\n",
    "        'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0'\n",
    "    }\n",
    "    \n",
    "    r = requests.get(url, headers=headers)\n",
    "    html = BeautifulSoup(r.content, 'html.parser')\n",
    "    metadata = {\n",
    "        'title': get_title(html),\n",
    "        'description': get_description(html),\n",
    "        'pdf': get_pdf(html),\n",
    "        'image': get_image(html),\n",
    "        'favicon': get_favicon(html, url),\n",
    "        'sitename': get_site_name(html, url),\n",
    "        'color': get_theme_color(html),\n",
    "        'url': url\n",
    "        }\n",
    "\n",
    "    return metadata\n",
    "\n",
    "\n",
    "def get_title(html):\n",
    "    \"\"\"Scrape page title.\"\"\"\n",
    "    title = None\n",
    "    if html.title.string:\n",
    "        title = html.title.string\n",
    "    elif html.find(\"meta\", property=\"og:title\"):\n",
    "        title = html.find(\"meta\", property=\"og:title\").get('content')\n",
    "    elif html.find(\"meta\", property=\"twitter:title\"):\n",
    "        title = html.find(\"meta\", property=\"twitter:title\").get('content')\n",
    "    elif html.find(\"h1\"):\n",
    "        title = html.find(\"h1\").string\n",
    "    return title\n",
    "\n",
    "def get_pdf(html):\n",
    "    return html.find(\"meta\",  {\"name\":\"citation_pdf_url\"}).get('content')\n",
    "\n",
    "def get_description(html):\n",
    "    \"\"\"Scrape page description.\"\"\"\n",
    "    description = None\n",
    "    if html.find(\"meta\", property=\"description\"):\n",
    "        description = html.find(\"meta\", property=\"description\").get('content')\n",
    "    elif html.find(\"meta\", property=\"og:description\"):\n",
    "        description = html.find(\"meta\", property=\"og:description\").get('content')\n",
    "    elif html.find(\"meta\", property=\"twitter:description\"):\n",
    "        description = html.find(\"meta\", property=\"twitter:description\").get('content')\n",
    "    elif html.find(\"p\"):\n",
    "        description = html.find(\"p\").contents\n",
    "    return description\n",
    "\n",
    "\n",
    "def get_image(html):\n",
    "    \"\"\"Scrape share image.\"\"\"\n",
    "    image = None\n",
    "    if html.find(\"meta\", property=\"image\"):\n",
    "        image = html.find(\"meta\", property=\"image\").get('content')\n",
    "    elif html.find(\"meta\", property=\"og:image\"):\n",
    "        image = html.find(\"meta\", property=\"og:image\").get('content')\n",
    "    elif html.find(\"meta\", property=\"twitter:image\"):\n",
    "        image = html.find(\"meta\", property=\"twitter:image\").get('content')\n",
    "    elif html.find(\"img\", src=True):\n",
    "        image = html.find_all(\"img\")[0].get('src')\n",
    "    return image\n",
    "\n",
    "\n",
    "def get_site_name(html, url):\n",
    "    \"\"\"Scrape site name.\"\"\"\n",
    "    if html.find(\"meta\", property=\"og:site_name\"):\n",
    "        site_name = html.find(\"meta\", property=\"og:site_name\").get('content')\n",
    "    elif html.find(\"meta\", property='twitter:title'):\n",
    "        site_name = html.find(\"meta\", property=\"twitter:title\").get('content')\n",
    "    else:\n",
    "        site_name = url.split('//')[1]\n",
    "        return site_name.split('/')[0].rsplit('.')[1].capitalize()\n",
    "    return sitename\n",
    "\n",
    "\n",
    "def get_favicon(html, url):\n",
    "    \"\"\"Scrape favicon.\"\"\"\n",
    "    if html.find(\"link\", attrs={\"rel\": \"icon\"}):\n",
    "        favicon = html.find(\"link\", attrs={\"rel\": \"icon\"}).get('href')\n",
    "    elif html.find(\"link\", attrs={\"rel\": \"shortcut icon\"}):\n",
    "        favicon = html.find(\"link\", attrs={\"rel\": \"shortcut icon\"}).get('href')\n",
    "    else:\n",
    "        favicon = f'{url.rstrip(\"/\")}/favicon.ico'\n",
    "    return favicon\n",
    "\n",
    "\n",
    "def get_theme_color(html):\n",
    "    \"\"\"Scrape brand color.\"\"\"\n",
    "    if html.find(\"meta\", property=\"theme-color\"):\n",
    "        color = html.find(\"meta\", property=\"theme-color\").get('content')\n",
    "        return color\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://patents.google.com/patent/US8104074B2/en\n",
      "https://patentimages.storage.googleapis.com/57/c5/c0/8164ac58ecb706/US8104074.pdf\n",
      "./PDF/Microsoft Corporation/US-8104074-B2.pdf\n",
      "us b negotiation the ability for the various parties of the digi tive embodiments one or more other specifications can be tal identity system to make agreements regarding mutu used to facilitate communications between the various sub ally acceptable technologies claims and other require systems in system ments in example embodiments principal relying party encapsulation the ability to exchange requirements and and identity provider can each utilize one or more a claims in a technology neutral way between parties computer systems each computer system includes one or subsystems and more of volatile and non volatile computer readable media transformation the ability to translate claims between computer readable media includes storage media as well as technologies and semantically removable and non removable media implemented in any one or more of these attributes can be found in the digital method or technology for storage of information such as identity systems described below computer readable instructions data structures program referring now to fig an example digital identity system modules or other data the computer system also includes is shown including a principal and a relying party communication media that typically embodies computer principal and relying party can communicate readable instructions data structures program modules or with each other over one or more networks such as the other data in a modulated data signal such as a carrier wave or internet in example embodiments principal can other transport mechanism and includes any information request goods services or other information from relying delivery media communication media includes wired media party relying party can require authentication of the such as a wired network or direct wired connection and identity of or information about principal before or in wireless media such as acoustic rf infrared and other wire conjunction with providing the requested goods services or less media combinations of any of the above should also be information to principal included within the scope of computer readable media also shown in fig is an example identity provider the computer system includes an operating system such including a claims transformer and a claims authority as the windows operating system from microsoft corpo the claims transformer is sometimes referred to as ration and one or more programs stored on the computer a security token service in the example shown identity readable media the computer system also includes one or provider can provide one or more claims about principal more input and output communications devices that allow the a claim is a statement or assertion made about the user to communicate with the computer system as well as principal related to the principal s identity or information allow the computer system to communicate with other about the principal such as for example name address devices communications between the computer systems social security number age etc as described further below used by principal relying party and identity provider identity provider i can provide claims to principal can be implemented using wired and or wireless tech and or relying party in the form of a signed security nologies token in example embodiments identity provider is in a referring now to fig example principal and relying trusted relationship with relying party so that relying party are again shown in the example shown principal party trusts the claims in the signed security token from sends a request to relying party for goods services or identity provider other information for example in one embodiment princi although claims transformer and claims authority pal sends a request to relying party for access to of identity provider are shown as separate entities in fig information from relying part that principal desires in alternative embodiments claims transformer and the request sent by principal can include a request for claims authority can be the same entity or different enti the authentication requirements of relying party using ties for example the mechanisms provided in ws metadatafx in example embodiments disclosed herein system is change in response to the request relying party sends implemented as an infocard system provided in the winfx principal requirements for relying party to authenti application programming interface developed by microsoft cate its identity or other information about principal the corporation of redmond wash the infocard system allows requirements of relying party for authentication are principals to manage multiple digital identities from various referred to herein as a security policy the security policy identity providers defines the set of claims from a trusted identity provider that the infocard system utilizes a web services platform such the principal must provide to relying party for relying as the windows communication foundation in the winfx party to authenticate principal application programming interface in addition the infocard in one example relying party specifies its security system is built using the web services security specifications policy using ws securitypolicy including both the claim propagated at least in part by microsoft corporation of red requirements and type of security token required by relying mond wash these specifications include a message security party a basic form for a security policy in accordance model ws security an endpoint policy ws security policy a with ws security policy is illustrated in the example below metadata protocol ws metadatafxchange and a trust model ws trust generally the ws security model describes how to attach security tokens to messages the ws securitypolicy model describes end point policy requirements such as sp requestsecuritytokentemplates required security tokens and supported encryption algo wst tokentype rithms such policy requirements can be conveyed and nego urn oasis names tc saml assertion tiated using a metadata protocol defined by ws metadatafx wst tokentype change the ws trust model describes a framework for trust wst claims wst dialect http schemas microsoft com ws models that enables different web services to interoperate identity s example embodiments described herein refer to the web ic claim services security specifications described above in alterna us b continued the policy can omit this element leaving the determination of the appropriate identity provider up to principal other uri http ws identity claims givenname s b ified in th li h elements can be specified in the security policy as well suc sp requestsecuritytokentemplate as for example the freshness of the required security token in some embodiments principal can require that rely ing party identify itself to principal so that principal can decide whether or not to satisfy the security policy of in this example one claim regarding the given name of the relying party as described below in one example relying principal is required by the security policy for authentication party identifies itself using an x certificate in other examples of other types of claims include without limitation embodiments relying party can identify itselfusing other the following mechanisms such as for example a secure sockets layer first name type xs string preferred name or first ssl server certificate name of a subject for example in one embodiment endpoint verification of last name type xs string surname or family name of relying party is provided using the provisions in ws a subject addressing such as the wsid identity element in the email address type xs string preferred address for example x v certificate shown below the to field of email to be sent to the subject usually of the form users a domaind street address type xs string street address compo nent of a subjects address information o water fwsa addr locality name or city type xs string locality compo nent of a subjects address information ds keyinfo state or province type xs string abbreviation for state ds x data or province name of a subjects address information ds x certificatex fols x certificates postal code type xs string postal code or zip code ds keyinfo component of a subjects address information country type xs string country of a subject wsa endpointreferences primary or home telephone number type xs string primary or home telephone number of a subject referring now to fig an example computer system secondary or work telephone number type ofprincipal includes one or more digital identities for xs string secondary or work telephone number of a principal these digital identities sometimes subject referred to as infocards in the infocard system provided in mobile telephone number type xs string mobile the winfx application programming interface developed by telephone number of a subject microsoft corporation of redmond wash are artifacts that date of birth type xs date the date of birth of a subject represent the token issuance relationship between principal in a form allowed by the xs date data type and a particular identity provider such an identity pro gender type xs token gender of a subject that can vider in the examples shown each digital identity have any of these exact string values male corresponds to a particular identity provider and principal female or unspecified and can have multiple digital identities from the same or private personal identifier type xs base binary indi different identity providers cates a private identifier that identifies the subject to a digital identities can include among other informa relying party tion s the identity provide r s issuance policy for security the security policy can also be used to specify the type of tokens including the type of tokens that can be issued the security token required by relying party or a default type claim types for which it has authority and or the credentials ca s i it e the say provider to use for authentication when requesting security tokens in example the above noted policy specifies a certain type o example embodiments digital identities are represented security token that is required by relying party see the as xml documents that are issued by identity providers wist tokentype element and stored by principals on a storage device such as in addition to specifying the required claims and token computer system an example format for a digital iden type the security policy can specify a specific identity pro ti g ity is provided below vider required by the relying party see the sp issuer ele ment as shown below ic infocardreferences sp issuedtoken sp usage xs anyuri ic cardid xs any uri ic cardid sp includetoken xs anyuri d ic cardversion xs unsignedint ic card version sp issuers ic infocardreferences xs string sp issuers ic cardimage mimetype xs string sp requestsecurity tokentemplate ic timeissued xs datetime ic timeissued xs datetime ic tokenservicereferences ic tokenservices wsa endpointreferences sp issuedtoken ic credentialhintoxs string ic credential hinto us b continued fic infocard ic tokenservicereferenceflic tokenservice ic credentialhint this optional element provides a ic usernamepasswordauthenticates hint string to be displayed to the user to help provide ic usernamepass the right credential wordauthenticatec ic kerberosv authenticate fic infocard ic tokenservicereferenceflic tokenservice this element provides ic x w authenticatex an unambiguous description of the credentials to use for ic x w authenticates authenticating to the security token service with ic selfissued authenticates example credential types including kerberos x or ic selfissued authenticates self issued credentials ic tokenservices ic infocard ic infocardpolicy this element provides ic tokenservicereferences the token issuance policy of the identity that allows a ic supportedtokentypes principal to determine if the infocard satisfies a relying party s token requirements in a given interaction ic supportedtokentypes ic infocard ic infocardpolicy ic supportedtoken types this element contains the list of token types as ic supportedclaim uri xs anyuri s ic displaytag xs string fic displaytag child elements that the identity provider can issue xs string ic infocard ic infocardpolicy ic supportedtokentypes ic supportedclaim ic tokentype one or more this element indicates an individual token type that is supported ic infocard ic infocardpolicy ic supportedclaims this element contains the list of claim types as child ele ic infocard ments that the identity provider can provide in security tokens the following describes the elements attributes of the digital ic infocard ic infocardpolicy ic supportedclaims ic identity format shown above supportedclaim one or more this element indicates fic infocard an infocard issued by an identity provider an individual claim type that is supported and fic infocard axml lang an optional language identifier ic infocard ic infocardpolicy ic requireappliesto using the language codes specified in rfc this optional empty element indicates that the service fic infocard ic infocardreference a specific reference requester infocard system must submit the relying for the infocard that should be used in future requests party identity to the identity provider for security tokens from the identity provider based on an example digital identity is provided below that infocard fic infocard ic infocardreferenceflic cardid this ele ment provides a globally unique identifier in the form of a uri for the specific infocard infocard xmlins http schemas fic infocard ic infocardreferenceflic card version this xmlins wsa http schemas xmlsoap org ws addressing optional element provides a versioning epoch for the xmlins wsp http schemas xmlsoap org ws policy infocard issuance infrastructure used by the identity xml lang en us provider infocardreference cardiddhttp cardidd fic infocard ic cardname this optional element pro infocardreferences vides a friendly textual name for the issued infocard fic infocard ic cardimage this optional element con tains a base encoded inline image that provides a xyz identity provider issuername timeissued to z timeissued graphical image for the issued infocard that can be tokenservicereferences displayed in user interfaces fic infocard ic cardimage a mimetype this attribute wsa endpointreferences provides a mime type specifying the format of the wsa address http wsa address included logo image ds keyinfo fic infocard ic issuername this element provides a ds x data friendly name for the issuer of the infocard ds x certificatex fols fic infocard ic timelissued this element provides the x certificates ds x data date and time when the infocard was issued ds keyinfo fic infocard ic timeexpires this optional element pro vides the date and time after which the infocard should wsa endpointreferences be treated as expired and invalid usernamepasswordauthenticate fic infocard ic tokenservicereference this element usernamepasswordauthenticatec provides an ordered list of child elements that specify the security token service endpoints the corresponding tokenservicereferences authentication method and credentials needed to request e ntypes security tokens tokentype uri fic infocard ic tokenservicereferenceflic tokenser urn oasis names tc saml assertion vice this element provides a security token service supportedtokentypes reference supportedclaim fic lnfocard ic tokenservicereferenceflic tokenservice uri http ws identity claims givenname wsa endpointreference this element provides the displaytag given name displaytag endpoint reference for the security token service us b an example of a request for a security token is provided continued below supportedclaims supportedclaim uri http ws identity claims surname displaytag last name supportedclaims wst tokentype urn oasis names tc saml assertion wst tokentype wst claims wst dialect http schemas microsoft com ws infocard identity s ic claim in the example above the digital identity is issued by xyz uri http ws identity claims givenname s identity provider and the digital identity states that xyz identity provider supports the security assertion markup language saml token type supportedtokentypes in another example below instead of requesting specific element provided in accordance with the saml standard claims from identity provider principal can simply promulgated by the organization for the advancement of provide a reference to one of its digital identities issued structured information standards oasis in addition by identity provider in its request the digital identity states that xyz identity provider can provide two claims supportedclaims element including givenname and surname requires the relying party s identity be included in the token request requireappli esto element and requires authentication based on user name password when requesting security tokens user ic infocardreferences ic cardid http xyz com cardid namepasswordauthenticate element d fa d sf fic cardid digital identities can be issued to principal using ic card version ic cardversion a variety of methods for example in some embodiments ic infocardreferences principal can request a digital identity over a hyper text transfer protocol connection or digital identities can be emailed from identity provider to principal in example embodiments identity provider signs each digi in example embodiments identity provider has its own security policy as specified in ws security policy and can tal identity sent to principal so that principal can verify that the digital identity is from identity provider require authentication of principal before identity pro vider forwards a security token to principal computer system also includes an identity selector generally claims authority of identity provider generally identity selector selects between one or can provide one or more of the claims required by the policy more digital identities of principal on computer from relying party for example claims authority is system to request and obtain security tokens from one or programmed to generate one or more claims request by prin more identity providers such as identity provider for cipal claims transformer of identity provider is example as described further below when a security policy programmed to transform the claims and to generate one or from relying party is received by computer identity more signed security tokens that include the claims selector is programmed to identify one or more digital in example embodiments claims transformer is pro identities that satisfy one or more of the claims required grammed to generate a security token that can be understood by the security policy using the information in digital identi by relying party as noted above principal can ties in one embodiment identity selector presents request a security token in a certain format see the wst the one or more relevant digital identities to principal tokentype element in the example request provided above and principal can decide whether or not to use digital in its request to identity provider based on requirements identities from relying party see the wst tokentype element in referring now to fig once principal receives the the example security policy provided above claims trans security policy from relying party principal can former can be programmed to generate security tokens in communicate with using for example computer one or more identity providers to gather the claims required by the one of a plurality of formats including without limitation policy in the example shown principal communicates x kerberos saml versions and simple the requirements of the security policy to identity provider extensible identity protocol sxip etc for example in one embodiment claims authority is in example embodiments principal requests one or programmed to generate claims in a first format a and the more security tokens from identity provider using the security policy of relying party requires a security token issuance mechanism described in ws trust in one example in a second format b claims transformer can transform principal forwards the claim requirements in the policy of the claims from claims authority from format a into relying party to identity provider the identity of format b before sending security token to principal relying party can but need not be specified in the request in addition claims transformer can be programmed to sent by principal to identity provider see the refine the semantics of aparticular claim in example embodi requireappliesto element in the example digital identity ments the semantics of a particular claim are transformed to described above the request can include other requirements minimize the amount of information provided in a particular as well such as a request for a display token as described claim and or security token to reduce or minimize the amount further below of personal information that is conveyed by a given claim us b for example in one embodiment the security policy of ic requesteddisplaytoken ic displaytoken ic display relying party requires a claim stating that principal is claim this element indicates an individual claim over years of age when this requirement is communicated returned in the security token to identity provider claims authority is programmed ic requesteddisplaytoken ic displaytoken ic display to provide a claim of the actual age of principal e g claim a uri this attribute provides the unique iden birth date jan when this claim is provided to tifier uri of the individual claim returned in the secu claims transformer claims transformer transforms rity token the semantics of the claim from the actual birth date of prin ic requesteddisplaytoken ic displaytoken ic display cipal to a claim that principal is over years of age claim ic displaytag this optional element provides a e g age true in this manner when this claim is common or friendly name for the claim returned in the packaged into security token that is forwarded through security token principal to relying party less personal information ic requesteddisplaytoken ic displaytoken ic display claim ic description this optional element provides a about principal is shared with relying party while the requirements of relying party are still met description of the semantics for the claim returned in the once security token is generated by claims trans security token ic requesteddisplaytoken ic displaytoken ic display former of identity provider security token can be forwarded to principal in example embodiments claims claim ic displayvalue this optional element provides transformer forwards the security token to principal one or more displayable values for the claim returned in using the response mechanisms described in ws trust the security token and fic requesteddisplaytoken ic displaytoken ic display in one embodiment claims transformer includes a secu rity token service sometimes referred to as an sts such as tokentext not shown this optional element provides that disclosed in u s patent application ser no an alternative textual representation of the entire token filed on may the entirety of which is hereby incor as a whole when the token content is not suitable for porated by reference display as individual claims referring now to fig an example security token is in some embodiments security token including com shown in the embodiment shown security token putational token is issued in accordance with the saml includes a computational token and a display token standard for example security token can be issued in computational token includes the claims provided by accordance with saml or saml standards other identity provider in an encrypted format claims trans standards can also be used such as for example and without former generates computational token in an limitation an x certificate and a kerberos ticket encrypted format that can be understood i e decrypted by in addition security token can be cryptographically relying party signed or endorsed by claims transformer using a known claims transformer also generates display token algorithm in one embodiment for example and without limi generally display token includes at least a summary of tation a bit asymmetric rivest shamir adleman the claims that are included in computational token of rsa key is used in other embodiments other encryption security token for example in some embodiments dis algorithms can be used such as for example a base play token includes a list of all of the claims included in encoded symmetric encryption key in one embodiment a computational token display token can be generated symmetric key is used by default in this manner in the in a format that can be reviewed by principal using for example shown a party such as relying party can cryp example computer system in some examples display tographically verify that security token originated from token is generated in a plain text format or a hypertext identity provider markup language format one example of a display token in example embodiments computational token is included as part of a security token response is shown below cryptographically bound to display token using one or more known algorithms such as a digital signature over the entire response message from the claims authority containing both the computational token and the display token in example embodiments a display token is provided by default in each security token issued by a claims transformer ic displayclaim uri http ws identity claims givenname in other embodiments a display token is provided only if the ic displaytag given name ic displaytag principal requests the display token an example of such a ic displayvalues john fic displayvalues display token request included in a security token request is as ic displayclaims follows ic displayclaim uri http ws identity claims surname ic displaytag lastname ic displaytag ic displayvalues doexic displayvalues the following is a general description of the elements shown the optional attribute langld indicates a language identi above in the display token fier for the display token using language codes specified in fic requesteddisplaytoken ic displaytoken the rfc returned display token in example embodiments a principal can review the dis fic requesteddisplaytoken ic displaytoken axml play information from the display token and decide whether lang this attribute indicates a language identifier using or not to forward the security token to a relying party in other the language codes specified in rfc in which the embodiments the principal can review the display informa display token content is localized tion but does not have the option to stop the forwarding of the us b security token to the relying party in other words once the a is an employee of company a for example the claim can security token is requested by the principal the security token be is employee of company a true next at operation is automatically forwarded to the relying party once the secu employee a s computer receives a signed security token rity token is received by the principal from the sts of company a the security token includes a in example embodiments if a security token lacks a dis computational token and a display token with the computa play token the principal is notified of the lack of the display tional token including the claim establishing that employee a token and the principal can decide whether or not to forward is an employee of company a the security token to the relying party in other embodiments control is then passed to operation and employee as if no display token is provided no display information is computer presents the summary of the claims from the dis presented to the principal play token to employee a for review in some embodiments in example embodiments only the computational token employee a is given the option to review the contents of the portion of a security token is forwarded by the principal to the security token using the display token and then decide relying party in other embodiments the principal forwards whether or not to forward the security token to the web site of the entire security token including both the computational travel agency a based on the information in the display token and the display token to the relying party token presented to employee a in other embodiments additional details about example embodiments of security employee a is not given the option regarding whether or not tokens including display tokens can be found in u s patent to forward the security token to travel agency a application ser no filed on dec the next at operation the security token is forwarded to entirety of which is hereby incorporated by reference the web site of travel agency a control is then passed to referring now to fig principal can forward secu operation and employee agains access to the requested rity token to relying party to satisfy all or a part of the discounted travel arrangements on the web site of travel security policy of relying party in one example principal agency a can forward security token to relying party by referring now to fig operation of method binding security token to an to application message using related to forwarding of a request based on the security policy the security binding mechanisms described in ws security of a relying party to an identity provider is shown in greater once relying party receives security token relying detail at operation the security policy from relying party party can cryptographically verify the origin of signed is reviewed at operation digital identities for security token relying party can also utilize the principal are reviewed to identify identity providers claims in computation token of security token to that can provide the claims required in the security policy satisfy the security policy of relying party to authenticate next at operation the relevant identity providers are principal once authentication is complete relying party identified based on the digital identities finally at operation can provide access to the goods services or other infor a request is forwarded to the relevant identity providers mation requested by principal for the requested claims in exampled disclosed herein communication between for example with reference to the non limiting example principal relying party and identity provider provided above once employee a s computer receives the can be conducted in a technology neutral fashion for security policy from the web site of travel agency a example the embodiments disclosed herein use the mecha employee a s computer reviews the digital identities on nisms provided in ws metadatafxchange and ws security employee a s computer to identify the identity providers that policy to facilitate communication between components can provide the claims required in the security policy once using different technologies and communication protocol the identity providers are identified employee a s computer formats in this manner the various components in digital sends requests one or more of the identified identity providers identity system can communicate with one another for security tokens including the required claims referring now to fig an example method for in some embodiments relying party identifies a par authenticating a principal is shown method is described ticular identity provider for a particular claim or set of claims with reference to a non limiting example in which the prin see the sp issuer element in the example security policy cipal is employee a employee a is an employee of a com provided above in this case principal can forward a pany referred to as company a and the relying party is a request to the appropriate identity provider for the required travel agency referred to as travel agency a company a claims in some embodiments the process of selecting iden has partnered with travel agency a for making travel tity providers can be automated by for example computer arrangements for employees of company a at discounted in other embodiments principal can be involved in rates the selection of identity providers at operation of method a principal requests infor referring now to fig an example method for an mation from a relying party in the example embodiment identity provider to generate a requested security token is employee a utilizes an application program on employee provided once again method is described with refer as computer to request travel arrangements from the web ence to the non limiting example provided above at opera site of travel agency a next at operation employee tion the identity provider for company a receives the as computer receives the security policy from the web site of request for claims forwarded by employee a next at opera travel agency a this policy requires that employee a sub tion company a generates the requested claims mit a security token with a claim establishing that employee control is then passed to operation wherein any trans a is an employee of company a before employee a can formation of the claims is conducted for example travel access the discounted travel arrangements on the web site of agency a can require a claim specifying that employee a is travel agency a an employee of company a the claims authority of com at operation employee a s computer forwards a pany a provides a claim stating that employee a is employee request based on the security policy to an identity provider number of company a e g employee a which in the present example is a security token service or the claims transformer of company a can transform this sts operated by company a the sts of company a can claim into a claim that simply indicates that employee a is an issue a security token with a claim establishing that employee employee of company a e g is employee of company us b a true thereby minimizing the amount of personal infor store a first digital identity at the first computer the first mation about employee a contained in the security token digital identity associated with the principal and a first next at operation the security token including the identity provider the first digital identity comprising claim is generated as part of the formation of the security a first xml document the first xml document con token the claims transformer of company a can transform taining a first claim list the first claim list specifying the security token into one of plurality of formats as required claims that the first identity provider is able to pro by the request or default finally at operation the secu vide rity token is forwarded to employee a store a second digital identity at the first computer the although in some of the embodiments disclosed herein the second digital identity associated with the principal principal is an individual in alternative embodiments the and a second identity provider the second digital principal can be a company an organization a computer or identity comprising a second xml document the other device a service or any other type of entity for second xml document containing a second claim example in one alternative embodiment the principal is a list the second claim list specifying claims that the device that is part of a network the device can request infor second identity provider is able to provide mation such as a software update from another device on the network functioning as a relying party the relying party can after storing the first digital identity and the second digital identity at the first computer send a request to require authentication of the identity of the device before the relying party provides the requested update the device can a relying party request one or more claims required by the security policy of receive a security policy from the relying party in the relying party from one or more claims transformers and response to the request the security policy compris the claims transformers can provide one or more security ing a third xml document the third xml document tokens including display tokens to the device the device can specifying a security token type required by the rely be programmed to review the contents of the display tokens ing party and specifying required claims and decide whether or not to forward the security token to the in response to receiving the security policy automati relying party based on its contents if the device forwards the cally determine based on a review of the claims speci security token to the relying party the relying party can then fied by the first claim list and the second claim list complete the authentication process and provide the that the first claim list specifies each of the required requested update to the device claims although example embodiments shown herein illustrate a after determining that the first claim list specifies each of security token that is forwarded by an identity provider to a the required claims send a first token request to the principal and then on to a relying party in alternative embodi first identity provider the first token request request ments the security token can be forwarded directly from the ing a first security token the first token request indi identity provider to the relying party for example in some cating one or more of the required claims specified by embodiments one security token including a computational the security policy token and possibly a display token can be forwarded to the relying party and another security token including a display receive the first security token from the first identity provider the first security token including a third token and possibly the computational token can be for warded to the principal other configurations are possible claim list the third claim list including the one or although the example embodiments shown herein illus more required claims specified by the security policy trate a security policy requiring only a single claim and a the first security token being of the security token type single security token issued by one identity provider in other specified by the security policy and embodiments a policy can require multiple claims and one or forward the security token to the relying party more identity providers can issue one or more security tokens the digital identity system of claim with one or more claims to satisfy the policy wherein one or more of the claims in the security token are there can be various advantages associated with digital semantically altered relative to claims provided by the identities systems configured as disclosed herein for first identity provider example example identity systems disclosed herein utilize the digital identity system of claim wherein the various subsystems that communicate or facilitate communi claims included in the first security token are semantically cation using a variety of protocols and message formats in altered so that the claims in the first security token reveal less addition such identity systems can automate the process of personal information about the principal than the claims pro gathering required authentication information further such vided by the first identity provider systems can increase user control and decrease personal the digital identity system of claim wherein execution information shared among subsystems of the system of the computer readable instructions further causes the first the various embodiments described above are provided by computer to way of illustration only and should not be construed to lim send a second token request to the first identity provider iting those skilled in the art will readily recognize various the second token request requesting a second security modifications and changes that may be made to the embodi token and ments described above without departing from the true spirit receive the second security token the second security and scope of the disclosure or the following claims token being of a different security token type what is claimed is the digital identity system of claim wherein the first a digital identity system the digital identity system computer receives the first security token from a second com comprising puter the second computer associated with the identity pro a first computer the first computer associated with a prin vider cipal the first computer comprising storage media that the digital identity system of claim wherein the first store computer readable instructions execution of the security token includes a computational token and a display computer readable instructions causing the first com token the computational token including the claims in the puter to third claim list in an encrypted format the display token us b including at least a summary of the claims in the third claim the method of claim further comprising list the summary in a format that can be reviewed by the sending by the second computer a request to a relying principal party for a security policy the digital identity system of claim receiving by the second computer the security policy from wherein the first digital identity includes an inline image a third computer the third computer associated with the that provides a graphical image for the digital identity relying party the security policy comprising a third that can be displayed in user interfaces a friendly name xml document the third xml document specifying for the digital identity and a friendly name for the issuer the security token type as being required by the relying of the digital identity and party and specifying the one or more claims related to wherein execution of the computer readable instructions the identity of the principal further cause the first computer to display the graphical sending by the second computer the request for the claims image the friendly name for the digital identity and the to the first computer and friendly name for the issuer of the digital identity to the after receiving the security token from the first computer principle forwarding by the second computer the security token the digital identity system of claim wherein prior to to the third computer storing the first digital identity and the second digital identity the method of claim further comprising execution of the computer readable instructions further receiving by the second computer a selection by the prin causes the first computer to cipal of a given digital identity of the principal from send a first digital identity request to the first identity pro among a plurality of digital identities of the principal vider stored at the second computer each digital identity in the receive the first digital identity from the first identity pro plurality of digital identities comprising an xml docu vider in response to the first digital identity request ment that represents a token issuance relationship send a second digital identity request to the second identity between the principal and a particular identity provider provider and and receive the second digital identity from the second identity selecting by the second computer the identity provider provider in response to the second digital identity based on the given digital identity request the method of claim wherein generating the security a method for providing a digital identity the method token further includes generating by the first computer the comprising security token to include a computational token and a display sending by a first computer a digital identity to a second token the computational token including the claims in an computer the first computer associated with an identity encrypted format the display token including at least a sum provider the second computer associated with a princi mary of the claims in a format that can be reviewed by the pal the digital identity comprising a first xml docu principal ment that contains a listing of claims that an identity a non transitory computer readable storage medium provider is able to provide the digital identity being an comprising computer executable instructions that when artifact that represents a token issuance relationship executed by a first computer cause the first computer to between the principal and the identity provider send a digital identity to a principal the digital identity after sending the digital identity to the second computer comprising a first xml document the first xml docu receiving by the first computer a token request from the ment containing second computer the token request requesting a security a listing of claims that an identity provider is able to token the token request comprising a second xml provide document the second xml document specifying one or a globally unique identifier for the digital identity more of the claims indicated by the digital identity the a date and time when the digital identity was issued second xml document specifying a security token type a hint to be displayed to the principle to help provide a in response to receiving the token request generating by right credential the first computer claims specified by the second xml an unambiguous description of credential to use for document authenticating to the identity provider after generating the claims transforming by the first com an inline image that provides a graphical image for the puter the claims digital identity that can be displayed in user inter after transforming the claims generating by the first com faces puter the security token the security token including the a date and time after which the digital identity is expired claims specified by the second xml document the a friendly name for the digital identity and security token being of the security token type specified a friendly name for the issuer of the digital identity and by the second xml document and a list of token types that the identity provider can sending by the first computer the security token to the issue second computer in response to the request wherein the digital identity being an artifact that represents the method of claim wherein transforming the a token issuance relationship between the principal and claims comprises altering by the first computer the claims the identity provider included in the security token semantically after sending the digital identity to the principal receive a the method of claim wherein altering the claims token request from a second computer the second com further comprises altering by the first computer the claims so puter associated with the principal the token request that the claims reveal less personal information about the requesting a security token the token request compris principal ing a second xml document the second xml docu the method of claim wherein transforming the ment specifying one or more requested claims the claims comprises formatting by the first computer the claims requested claims related to an identity of the principal from one format into another format the requested claims being among the claims in the us b listing of claims contained by the digital identity the after encrypting the requested claims generate the security second xml document specifying a security token type token the security token including a computational generate the requested claims in a first format token and a display token the computational token being of the security token type specified by the second transform the requested claims such that the requested claims xml document the computational token including the are formatted in a second format and such that the requested requested claims the display token including each of the claims are altered semantically such that the requested claims requested claims in a format that can be reviewed by the reveal less personal information about the principal the sec principal the display token cryptographically bound to ond format being a format required by the relying party the the computational token and second format being different from the first format send the security token to the second computer after transforming the requested claims into the second format encrypt the requested claims k \n",
      "[('ic cardversion xs unsignedint ic card version sp issuers ic infocardreferences xs string sp issuers ic cardimage mimetype xs string sp requestsecurity tokentemplate ic timeissued xs datetime ic timeissued xs datetime ic tokenservicereferences ic tokenservices wsa endpointreferences sp issuedtoken ic credentialhintoxs string ic credential hinto', 998.8092942771509), ('ntypes security tokens tokentype uri fic infocard ic tokenservicereferenceflic tokenser urn oasis names tc saml assertion vice', 188.77091421934628), ('supportedclaims wst tokentype urn oasis names tc saml assertion wst tokentype wst claims wst dialect http schemas microsoft', 188.67977656639079), ('ic displayclaim uri http ws identity claims surname ic displaytag lastname ic displaytag ic displayvalues doexic displayvalues', 176.94063502886718), ('security token service supportedtokentypes reference supportedclaim fic lnfocard ic tokenservicereferenceflic tokenservice uri http ws identity claims givenname wsa endpointreference', 173.50866223975154), ('ic infocardreferences sp issuedtoken sp usage xs anyuri ic cardid xs', 162.5760430046144), ('issue xs string ic infocard ic infocardpolicy ic supportedtokentypes ic supportedclaim ic tokentype', 138.36332656890147), ('specific infocard infocard xmlins http schemas fic infocard ic infocardreferenceflic card version', 130.12166468838944), ('wsa address http wsa address included logo image ds keyinfo fic infocard ic issuername', 126.27544024887231), ('credential wordauthenticatec ic kerberosv authenticate fic infocard ic tokenservicereferenceflic tokenservice', 101.74914551186328)]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import pdfplumber\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "def pre_process(text):\n",
    "    \n",
    "    # lowercase\n",
    "    text=text.lower()\n",
    "    \n",
    "    #remove tags\n",
    "    text=re.sub(\"</?.*?>\",\" <> \",text)\n",
    "    \n",
    "    # remove special characters and digits\n",
    "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def get_stop_words(stop_file_path):\n",
    "    \"\"\"load stop words \"\"\"\n",
    "    \n",
    "    with open(stop_file_path, 'r', encoding=\"utf-8\") as f:\n",
    "        stopwords = f.readlines()\n",
    "        stop_set = set(m.strip() for m in stopwords)\n",
    "        return frozenset(stop_set)\n",
    "    \n",
    "def sort_coo(coo_matrix):\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
    "\n",
    "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
    "    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
    "    \n",
    "    #use only topn items from vector\n",
    "    sorted_items = sorted_items[:topn]\n",
    "\n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "\n",
    "    for idx, score in sorted_items:\n",
    "        fname = feature_names[idx]\n",
    "        \n",
    "        #keep track of feature name and its corresponding score\n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_names[idx])\n",
    "\n",
    "    #create a tuples of feature,score\n",
    "    #results = zip(feature_vals,score_vals)\n",
    "    results= {}\n",
    "    for idx in range(len(feature_vals)):\n",
    "        results[feature_vals[idx]]=score_vals[idx]\n",
    "    \n",
    "    return results\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "for index, row in microsoft.iterrows():\n",
    "    url = row['Result']\n",
    "    print(url)\n",
    "    #print(get_download_url(url))\n",
    "    data = scrape_page_metadata(url)\n",
    "    \n",
    "    pdfURL = data[\"pdf\"]\n",
    "    print(pdfURL)\n",
    "    \n",
    "    path = \"./PDF/\" + row['Assignee']\n",
    "    Path(path).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    path = \"./PDF/\" + row['Assignee'] + '/' + row['ID'] + \".pdf\"\n",
    "    print(path)\n",
    "    urllib.request.urlretrieve(pdfURL, path)\n",
    "    \n",
    "    pages = list()\n",
    "    fulltext = \"\";\n",
    "    count = 0;\n",
    "    with pdfplumber.open(path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text = page.extract_text()\n",
    "            text = pre_process(text)\n",
    "            \n",
    "            pages.append(text)\n",
    "            count = count +1;\n",
    "            if count > 15:\n",
    "                fulltext = fulltext + text;\n",
    "\n",
    "            #load a set of stop words\n",
    "        stopwords=get_stop_words(\"./Files/stopwords.txt\")\n",
    "\n",
    "        #get the text column \n",
    "        #docs=df_idf['text'].tolist()\n",
    "\n",
    "        #create a vocabulary of words, \n",
    "        #ignore words that appear in 85% of documents, \n",
    "        #eliminate stop words\n",
    "        cv = CountVectorizer(max_df = 1, stop_words = stopwords, max_features = 10000)\n",
    "        word_count_vector = cv.fit_transform(pages)  \n",
    "            \n",
    "        feature_names=cv.get_feature_names()\n",
    "        #print(feature_names)\n",
    "        \n",
    "        from multi_rake import Rake\n",
    "\n",
    "        rake = Rake()\n",
    "        rake.max_words = 100000\n",
    "\n",
    "        keywords = rake.apply(fulltext)\n",
    "        \n",
    "        print(fulltext)\n",
    "\n",
    "        print(keywords[:10])\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: multi_rake in c:\\programdata\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: cld2-cffi>=0.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from multi_rake) (0.1.4)\n",
      "Requirement already satisfied: regex>=2018.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from multi_rake) (2020.6.8)\n",
      "Requirement already satisfied: pyrsistent>=0.14.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from multi_rake) (0.16.0)\n",
      "Requirement already satisfied: numpy>=1.14.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from multi_rake) (1.18.5)\n",
      "Requirement already satisfied: cffi in c:\\programdata\\anaconda3\\lib\\site-packages (from cld2-cffi>=0.1.4->multi_rake) (1.14.0)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from cld2-cffi>=0.1.4->multi_rake) (1.15.0)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi->cld2-cffi>=0.1.4->multi_rake) (2.20)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
